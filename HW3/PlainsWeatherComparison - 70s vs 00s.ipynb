{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T17:51:27.625258Z",
     "start_time": "2020-05-20T17:51:27.080773Z"
    }
   },
   "outputs": [],
   "source": [
    "import os.path as path\n",
    "import sys\n",
    "import numpy as np\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from lib import *\n",
    "from pyspark.sql import *\n",
    "# from utils import *\n",
    "from lib.utils import *\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "%pylab inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T17:51:30.328556Z",
     "start_time": "2020-05-20T17:51:27.814731Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a new spark and sql context\n",
    "sc = create_sc(pyFiles=['lib/numpy_pack.py','lib/spark_PCA.py','lib/computeStatistics.py'])\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "# Create the names of the files/directories we're working with\n",
    "data_dir = '../DataHW3'\n",
    "\n",
    "if not path.exists(data_dir + '/' + 'stations.parquet'):\n",
    "    getStations()\n",
    "\n",
    "    \n",
    "states = ['ND', 'SD', 'MN', 'IA', 'NE', 'TX', 'OK', 'KS']\n",
    "\n",
    "for s in states:\n",
    "    \n",
    "    parquet = s + '.parquet'\n",
    "    tarname = s + '.tgz'\n",
    "    \n",
    "    if not path.exists(data_dir + '/' + parquet):\n",
    "\n",
    "        # pull the weather data for a particular state from the MAS-DSE S3 bucket\n",
    "        getStateData(s, data_dir, tarname, parquet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change in average daily snow fall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-20T17:53:19.213647Z",
     "start_time": "2020-05-20T17:51:36.542649Z"
    }
   },
   "outputs": [],
   "source": [
    "featureStr = \"\\'SNOW\\'\"\n",
    "\n",
    "test_data = decadeMeasurementDelta(featureStr, states, data_dir, sqlContext)\n",
    "master_dataframe = test_data[0]\n",
    "for i in range(len(test_data)-1):\n",
    "    master_dataframe = master_dataframe.union(test_data[i+1])\n",
    "\n",
    "print(\"\\n\\nAmount of snow fall change, 70s to 00s\")\n",
    "\n",
    "plotter = leaflet(sqlContext, featureStr)\n",
    "plotter.add(master_dataframe)\n",
    "plotter.plot_all()\n",
    "plotter.m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:42:01.061120Z",
     "start_time": "2020-05-16T01:42:00.934219Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "plotter.color_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change in average daily snow depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:43:54.258087Z",
     "start_time": "2020-05-16T01:42:01.064915Z"
    }
   },
   "outputs": [],
   "source": [
    "featureStr = \"\\'SNWD\\'\"\n",
    "\n",
    "test_data = decadeMeasurementDelta(featureStr, states, data_dir, sqlContext)\n",
    "master_dataframe = test_data[0]\n",
    "for i in range(len(test_data)-1):\n",
    "    master_dataframe = master_dataframe.union(test_data[i+1])\n",
    "\n",
    "print(\"\\n\\nChange in snow depth change, 70s to 00s\")\n",
    "\n",
    "plotter = leaflet(sqlContext, featureStr)\n",
    "plotter.add(master_dataframe)\n",
    "plotter.plot_all()\n",
    "plotter.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:43:54.347772Z",
     "start_time": "2020-05-16T01:43:54.265802Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "plotter.color_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:55:40.619320Z",
     "start_time": "2020-05-14T17:55:36.037090Z"
    }
   },
   "source": [
    "# Change in average max daily temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:45:19.687497Z",
     "start_time": "2020-05-16T01:43:54.349251Z"
    }
   },
   "outputs": [],
   "source": [
    "featureStr = \"\\'TMAX\\'\"\n",
    "\n",
    "test_data = decadeMeasurementDelta(featureStr, states, data_dir, sqlContext)\n",
    "master_dataframe = test_data[0]\n",
    "for i in range(len(test_data)-1):\n",
    "    master_dataframe = master_dataframe.union(test_data[i+1])\n",
    "\n",
    "print(\"\\n\\nChange in average max daily temperature, 70s to 00s\")\n",
    "\n",
    "plotter = leaflet(sqlContext, featureStr)\n",
    "plotter.add(master_dataframe)\n",
    "plotter.plot_all()\n",
    "plotter.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:45:19.761103Z",
     "start_time": "2020-05-16T01:45:19.696258Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "plotter.color_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-14T17:55:41.000973Z",
     "start_time": "2020-05-14T17:55:40.996208Z"
    }
   },
   "source": [
    "# Change in average min daily temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:46:43.524421Z",
     "start_time": "2020-05-16T01:45:19.762864Z"
    }
   },
   "outputs": [],
   "source": [
    "featureStr = \"\\'TMIN\\'\"\n",
    "\n",
    "test_data = decadeMeasurementDelta(featureStr, states, data_dir, sqlContext)\n",
    "master_dataframe = test_data[0]\n",
    "for i in range(len(test_data)-1):\n",
    "    master_dataframe = master_dataframe.union(test_data[i+1])\n",
    "\n",
    "print(\"\\n\\nChange in average min daily temperature, 70s to 00s\")\n",
    "\n",
    "plotter = leaflet(sqlContext, featureStr)\n",
    "plotter.add(master_dataframe)\n",
    "plotter.plot_all()\n",
    "plotter.m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:46:43.632023Z",
     "start_time": "2020-05-16T01:46:43.527071Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "plotter.color_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification of 'TX' values\n",
    "\n",
    "Verification that the SNOW and SNWD metrics actually saw an average increase comparing across the two time periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:46:43.638881Z",
     "start_time": "2020-05-16T01:46:43.633654Z"
    }
   },
   "outputs": [],
   "source": [
    "featureStr = \"\\'SNWD\\'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:46:44.246273Z",
     "start_time": "2020-05-16T01:46:43.643554Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = '../DataHW3'\n",
    "s = 'TX'\n",
    "parquet = s + '.parquet'\n",
    "parquet_path = data_dir + '/' + parquet\n",
    "df = sqlContext.read.parquet(parquet_path)\n",
    "sqlContext.registerDataFrameAsTable(df,f'table_{s}')\n",
    "\n",
    "# 70s\n",
    "\n",
    "###\n",
    "Query = f\"\"\"\n",
    "SELECT Station, Measurement, Values, longitude, latitude, Year\n",
    "FROM table_{s}\n",
    "WHERE Measurement=={featureStr} and (Year >= 1970 and Year < 1980)\n",
    "\"\"\"\n",
    "query70s = sqlContext.sql(Query)\n",
    "rdd70s = query70s.rdd.map(lambda x: remove0sAndAverage(x, 'Values'))\n",
    "dfs70 = sqlContext.createDataFrame(rdd70s)\n",
    "sqlContext.registerDataFrameAsTable(dfs70, f'table_{s}_70s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:46:46.728437Z",
     "start_time": "2020-05-16T01:46:44.248467Z"
    }
   },
   "outputs": [],
   "source": [
    "df70 = dfs70.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:46:47.318634Z",
     "start_time": "2020-05-16T01:46:46.730590Z"
    }
   },
   "outputs": [],
   "source": [
    "# 00s\n",
    "\n",
    "###\n",
    "Query = f\"\"\"\n",
    "SELECT Station, Measurement, Values, longitude, latitude, Year\n",
    "FROM table_{s}\n",
    "WHERE Measurement=={featureStr} and (Year >= 2000 and Year < 2010)\n",
    "\"\"\"\n",
    "query00s = sqlContext.sql(Query)\n",
    "rdd00s = query00s.rdd.map(lambda x: remove0sAndAverage(x, 'Values'))\n",
    "dfs00 = sqlContext.createDataFrame(rdd00s)\n",
    "sqlContext.registerDataFrameAsTable(dfs00, f'table_{s}_00s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:46:49.993656Z",
     "start_time": "2020-05-16T01:46:47.321552Z"
    }
   },
   "outputs": [],
   "source": [
    "df00 = dfs00.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T01:46:50.002082Z",
     "start_time": "2020-05-16T01:46:49.996205Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Mean TX SNOW values in the 70s: %s\"%df70.Values.mean())\n",
    "print(\"Mean TX SNOW values in the 00s: %s\"%df00.Values.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
